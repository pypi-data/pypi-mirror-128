# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/examples/complex_dummy_experiment_manager.ipynb (unless otherwise specified).

__all__ = ['ComplexDummyExperimentManager', 'run_multiple_experiments', 'remove_previous_experiments']

# Cell
from .dummy_experiment_manager import DummyExperimentManager, FakeModel
import hpsearch
import os
from ..visualization import plot_utils

class ComplexDummyExperimentManager (DummyExperimentManager):

    def run_experiment (self, parameters={}, path_results='./results'):
        # extract hyper-parameters used by our model. All the parameters have default values if they are not passed.
        offset = parameters.get('offset', 0.5)   # default value: 0.5
        rate = parameters.get('rate', 0.01)   # default value: 0.01
        epochs = parameters.get('epochs', 10) # default value: 10
        noise = parameters.get('noise', 0.0)

        # other parameters that do not form part of our experiment definition
        # changing the values of these other parameters, does not make the ID of the experiment change
        verbose = parameters.get('verbose', True)

        # build model with given hyper-parameters
        model = FakeModel (offset=offset, rate=rate, epochs=epochs, noise = noise, verbose=verbose)

        # load training, validation and test data (fake step)
        model.load_data()

        # load previous model if exists
        if not model.load_model_and_history (path_results):
            # start from previous experiment if indicated by parameters
            path_results_previous_experiment = parameters.get('prev_path_results','')
            model.load_model_and_history (path_results_previous_experiment)

        # fit model with training data
        model.fit ()

        # save model weights and evolution of accuracy metric across epochs
        model.save_model_and_history(path_results)

        # evaluate model with validation and test data
        validation_accuracy, test_accuracy = model.score()

        # store model
        self.model = model

        # the function returns a dictionary with keys corresponding to the names of each metric.
        # We return result on validation and test set in this example
        dict_results = dict (validation_accuracy = validation_accuracy,
                             test_accuracy = test_accuracy)

        return dict_results



# Cell
import shutil
import os

def run_multiple_experiments (nruns=1, noise=0.0, verbose=True, rate=0.03):
    em = ComplexDummyExperimentManager ()
    parameters_single_value = dict(rate=rate, noise=noise)   # parameters where we use a fixed value
    parameters_multiple_values=dict(offset=[0.1, 0.3, 0.6], epochs=[5, 15, 30]) # parameters where we try multiple values
    other_parameters = dict(verbose=verbose) # parameters that control other aspects that are not part of our experiment definition (a new experiment is not created if we assign different values for these parametsers)
    em.grid_search (log_message='fixed rate, multiple epochs values',
            parameters_single_value=parameters_single_value,
            parameters_multiple_values=parameters_multiple_values,
            other_parameters=other_parameters,
            nruns=nruns)

def remove_previous_experiments():
    em = ComplexDummyExperimentManager ()
    path_results = em.get_path_experiments()
    if os.path.exists(path_results):
        shutil.rmtree(path_results)