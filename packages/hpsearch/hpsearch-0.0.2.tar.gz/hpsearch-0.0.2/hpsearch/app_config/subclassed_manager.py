# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/experiments.bp_expmanager.ipynb (unless otherwise specified).

__all__ = ['BPExperimentManager']

# Cell
from ..pipeline.athena_pipeline import AthenaPipeline
import athena_ml.config.defaults as dflt
import athena_ml.config.pipeline_config as config

from hpsearch.experiment_manager import ExperimentManager

# Cell
class BPExperimentManager (ExperimentManager):

    def __init__ (self):
        super().__init__()

    def run_experiment (self, parameters={}, path_results='./results'):

        bp_classifier = parameters.get('bp_classifier', 'rule_based')

        if bp_classifier=='rule_based':
            training_config = config.bp_training.copy()
        elif bp_classifier=='svm':
            training_config = config.bp_training_svm.copy()
        else:
            raise ValueError (f'{bp_classifier} not recognized')

        training_config.update(**parameters)
        training_config.update(path_results=path_results)

        # run inference
        athena_pipeline = AthenaPipeline (**training_config)

        # results
        dict_results = athena_pipeline.run()

        return dict_results

    # implementing the following method is not necessary but recommended
    def get_default_parameters (self, parameters):
        """Indicate the default value for each of the hyper-parameters used."""
        defaults = dict(bp_classifier='rule_based')
        bp_classifier = parameters.get('bp_classifier', 'rule_based')
        if bp_classifier=='rule_based':
            training_config = config.bp_training.copy()
        elif bp_classifier=='svm':
            training_config = config.bp_training_svm.copy()
        else:
            raise ValueError (f'{bp_classifier} not recognized')
        defaults.update (training_config)

        return defaults

    # implementing the following method is not necessary but recommended
    def get_path_experiments (self, path_experiments = None, folder = None):
        """Gives the root path to the folder where results of experiments are stored."""
        path_experiments = 'remote_data/hpsearch/bp_detector'

        if folder != None:
            path_experiments = f'{path_experiments}/{folder}'

        return path_experiments


    # implementing the following method is not necessary but recommended
    def get_default_operations (self):
        default_operations = dict (root='',
                                   metric='f1',
                                   op='max')

        return default_operations